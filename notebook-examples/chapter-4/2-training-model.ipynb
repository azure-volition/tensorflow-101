{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install matplotlib\n",
    "#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple seaborn\n",
    "#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 正则化函数\n",
    "def normalize_feature(df):\n",
    "    return df.apply(lambda column: (column - column.mean()) / column.std())\n",
    "\n",
    "# 载入csv\n",
    "df = normalize_feature(pd.read_csv('data1.csv',\n",
    "                                   names=['square', 'bedrooms', 'price']))\n",
    "\n",
    "# ones是n行1列的数据框，表示x0恒为1\n",
    "ones = pd.DataFrame({'ones': np.ones(len(df))})\n",
    "# 根据列合并数据\n",
    "df = pd.concat([ones, df], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理：获取 X 和 y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0:3]: 第0，1，2列\n",
    "X_data = np.array(df[df.columns[0:3]])\n",
    "# [-1]: 最后一列，reshape是为了把(47,0)变成形状(47,1)\n",
    "y_data = np.array(df[df.columns[-1]]).reshape(len(df), 1)\n",
    "\n",
    "print(X_data.shape, type(X_data))\n",
    "print(y_data.shape, type(y_data))\n",
    "\n",
    "for i in [0,1,2]:\n",
    "    print(X_data.take(i,0))\n",
    "    print(y_data.take(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建线性回归模型（数据流图）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "alpha = 0.01 # 学习率 alpha\n",
    "epoch = 500  # 训练全量数据集的轮数\n",
    "\n",
    "# 用占位符定义输入数据的数据类型和形状\n",
    "# 输入 X，类型float，形状[47, 3]\n",
    "print(X_data.shape)\n",
    "print(y_data.shape)\n",
    "X = tf.placeholder(tf.float32, X_data.shape)\n",
    "# 输出 y，类型float，形状[47, 1]\n",
    "y = tf.placeholder(tf.float32, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 权重变量 W，形状(3,1)\n",
    "#   X_data.shape[0]: 第0维的维度数47（47个样本）\n",
    "#   X_data.shape[1]: 第1维的维度数3 （3个特征）\n",
    "#   因此根据第2个参数，权重变量W的形状是 (3,1)\n",
    "# 使用constant_initializer来初始化，初始化为全1\n",
    "# tf.get_variable相比tf.variable可以从checkpoint中加载时可以快速找到这些变量的值\n",
    "# 同时也支持变量的复用，单独的initializer的初始化\n",
    "# W = tf.get_variable(\"weights\", (X_data.shape[1], 1), initializer=tf.constant_initializer((1.0,1.0,1.0)))\n",
    "W = tf.get_variable(\"weights\", (X_data.shape[1], 1), initializer=tf.constant_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设函数 h(x) = w0*x0+w1*x1+w2*x2, 其中x0恒为1\n",
    "# 推理值 y_pred  形状[47,1]\n",
    "y_pred = tf.matmul(X, W)\n",
    "\n",
    "# 损失函数采用最小二乘法，y_pred - y 是形如[47, 1]的向量。\n",
    "# tf.matmul(a,b,transpose_a=True) 表示：矩阵a的转置乘矩阵b，即 [1,47] X [47,1]\n",
    "# tranpose_a = True表示对第一个参数做转置\n",
    "# 损失函数操作 loss\n",
    "loss_op = 1 / (2 * len(X_data)) * tf.matmul((y_pred - y), (y_pred - y), transpose_a=True)\n",
    "# 随机梯度下降优化器 opt\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=alpha)\n",
    "# 单轮训练操作 train_op\n",
    "train_op = opt.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建会话（运行环境）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [0,1,2]:\n",
    "#    print(X_data.take(i,0))\n",
    "#    print(y_data.take(i))\n",
    "# print(train_op)\n",
    "# print(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # 初始化全局变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 开始训练模型，\n",
    "    # 因为训练集较小，所以每轮都使用全量数据训练\n",
    "    for e in range(1, epoch + 1):\n",
    "        sess.run(train_op, feed_dict={X: X_data, y: y_data})\n",
    "        if e % 10 == 0:\n",
    "            loss, w = sess.run([loss_op, W], feed_dict={X: X_data, y: y_data})\n",
    "            log_str = \"Epoch %d \\t Loss=%.4g \\t Model: y = %.4gx1 + %.4gx2 + %.4g\"\n",
    "            print(log_str % (e, loss, w[1], w[2], w[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
